{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    f = open(\"abalone.txt\", 'r')\n",
    "    o = open(\"abaloneProcessed.txt\", 'w')\n",
    "    c = f.read(1)\n",
    "    while True:\n",
    "        if not c:\n",
    "            break\n",
    "        if c == 'M':\n",
    "            o.write('1')\n",
    "        elif c == 'F':\n",
    "            o.write('-1')\n",
    "        elif c == 'I':\n",
    "            o.write('0')\n",
    "        else:\n",
    "            o.write(c)\n",
    "        c = f.read(1)\n",
    "    f.close()\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctPercentage(svm, x, y, rango):\n",
    "    array = svm.predict(x) #Guardamos los valores de la funciÃ³n sigmoide en el array \n",
    "    #aprobados = (array >= 0.5) #Guardamos en un array los aprobados(\"true\") y suspensos(\"false\")\n",
    "    cmp = (np.abs(array - y) <= rango) #Comparamos con los resultados originales y guardamos las coincidencias(\"true\")\n",
    "    return np.sum(cmp)/len(y)*100 #Devolvemos el porcentaje de acierto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    data = np.genfromtxt('abaloneProcessed.txt', delimiter=',')\n",
    "    \n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    join = np.hstack((x, np.c_[y]))\n",
    "    np.random.shuffle(join)\n",
    "    \n",
    "    #Se vuelven a separar tras barajearse\n",
    "    xShuffled = join[:,:-1]\n",
    "    yShuffled = join[:,-1]\n",
    "    \n",
    "    xTraining = xShuffled[:2700]\n",
    "    yTraining = yShuffled[:2700]\n",
    "    xVal = xShuffled[2700:3800]\n",
    "    yVal = yShuffled[2700:3800]\n",
    "    xTest = xShuffled[3800:]\n",
    "    yTest = yShuffled[3800:]\n",
    "    \n",
    "    return xTraining, yTraining, xVal, yVal, xTest, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(rango): \n",
    "    \n",
    "    xTraining, yTraining, xVal, yVal, xTest, yTest = loadData()\n",
    "    bestvalue = -1\n",
    "    nums = np.array([0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30])\n",
    "    \n",
    "    for sigma in nums:\n",
    "        for c in nums:\n",
    "            svm = SVC(kernel='rbf', C=c ,gamma=1 / (2 * sigma**2))\n",
    "            svm.fit(xTraining,yTraining)\n",
    "            per = correctPercentage(svm,xVal,yVal, rango)\n",
    "            perEnt = correctPercentage(svm,xTraining,yTraining, rango)\n",
    "            if per >= bestvalue:\n",
    "                bestc = c\n",
    "                bestsigma = sigma\n",
    "                bestvalue = per\n",
    "                bestsvm = svm\n",
    "            print(\"%.2f para C = %.2f y sigma = %.2f\" % (per, c, sigma))\n",
    "            print(\"#%.2f para C = %.2f y sigma = %.2f (entrenamiento)\" % (perEnt, c, sigma))\n",
    "    \n",
    "    print(\"Mejor porcentaje de acierto sobre los ejemplos de validaciÃ³n: %.2f\" % bestvalue)\n",
    "    #y = y + 1.5\n",
    "    svm = SVC(kernel='rbf', C=30 ,gamma=1 / (2 * 0.01**2))\n",
    "    svm.fit(xTraining,yTraining)\n",
    "    print(svm.predict(xVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.36 para C = 0.01 y sigma = 0.01\n",
      "#66.81 para C = 0.01 y sigma = 0.01 (entrenamiento)\n",
      "65.36 para C = 0.03 y sigma = 0.01\n",
      "#66.81 para C = 0.03 y sigma = 0.01 (entrenamiento)\n",
      "65.36 para C = 0.10 y sigma = 0.01\n",
      "#66.81 para C = 0.10 y sigma = 0.01 (entrenamiento)\n",
      "65.36 para C = 0.30 y sigma = 0.01\n",
      "#66.81 para C = 0.30 y sigma = 0.01 (entrenamiento)\n",
      "70.73 para C = 1.00 y sigma = 0.01\n",
      "#99.78 para C = 1.00 y sigma = 0.01 (entrenamiento)\n",
      "70.91 para C = 3.00 y sigma = 0.01\n",
      "#100.00 para C = 3.00 y sigma = 0.01 (entrenamiento)\n",
      "70.91 para C = 10.00 y sigma = 0.01\n",
      "#100.00 para C = 10.00 y sigma = 0.01 (entrenamiento)\n",
      "70.91 para C = 30.00 y sigma = 0.01\n",
      "#100.00 para C = 30.00 y sigma = 0.01 (entrenamiento)\n",
      "65.36 para C = 0.01 y sigma = 0.03\n",
      "#66.81 para C = 0.01 y sigma = 0.03 (entrenamiento)\n",
      "65.36 para C = 0.03 y sigma = 0.03\n",
      "#66.81 para C = 0.03 y sigma = 0.03 (entrenamiento)\n",
      "69.91 para C = 0.10 y sigma = 0.03\n",
      "#70.93 para C = 0.10 y sigma = 0.03 (entrenamiento)\n",
      "73.73 para C = 0.30 y sigma = 0.03\n",
      "#74.00 para C = 0.30 y sigma = 0.03 (entrenamiento)\n",
      "76.36 para C = 1.00 y sigma = 0.03\n",
      "#92.67 para C = 1.00 y sigma = 0.03 (entrenamiento)\n",
      "76.09 para C = 3.00 y sigma = 0.03\n",
      "#98.74 para C = 3.00 y sigma = 0.03 (entrenamiento)\n",
      "74.36 para C = 10.00 y sigma = 0.03\n",
      "#99.70 para C = 10.00 y sigma = 0.03 (entrenamiento)\n",
      "74.09 para C = 30.00 y sigma = 0.03\n",
      "#99.89 para C = 30.00 y sigma = 0.03 (entrenamiento)\n",
      "65.36 para C = 0.01 y sigma = 0.10\n",
      "#66.81 para C = 0.01 y sigma = 0.10 (entrenamiento)\n",
      "70.91 para C = 0.03 y sigma = 0.10\n",
      "#72.19 para C = 0.03 y sigma = 0.10 (entrenamiento)\n",
      "74.09 para C = 0.10 y sigma = 0.10\n",
      "#74.48 para C = 0.10 y sigma = 0.10 (entrenamiento)\n",
      "77.64 para C = 0.30 y sigma = 0.10\n",
      "#78.59 para C = 0.30 y sigma = 0.10 (entrenamiento)\n",
      "78.73 para C = 1.00 y sigma = 0.10\n",
      "#81.30 para C = 1.00 y sigma = 0.10 (entrenamiento)\n",
      "79.73 para C = 3.00 y sigma = 0.10\n",
      "#86.15 para C = 3.00 y sigma = 0.10 (entrenamiento)\n",
      "78.82 para C = 10.00 y sigma = 0.10\n",
      "#91.22 para C = 10.00 y sigma = 0.10 (entrenamiento)\n",
      "75.36 para C = 30.00 y sigma = 0.10\n",
      "#94.78 para C = 30.00 y sigma = 0.10 (entrenamiento)\n",
      "65.36 para C = 0.01 y sigma = 0.30\n",
      "#66.81 para C = 0.01 y sigma = 0.30 (entrenamiento)\n",
      "72.73 para C = 0.03 y sigma = 0.30\n",
      "#73.93 para C = 0.03 y sigma = 0.30 (entrenamiento)\n",
      "75.73 para C = 0.10 y sigma = 0.30\n",
      "#77.04 para C = 0.10 y sigma = 0.30 (entrenamiento)\n",
      "76.55 para C = 0.30 y sigma = 0.30\n",
      "#78.04 para C = 0.30 y sigma = 0.30 (entrenamiento)\n",
      "77.18 para C = 1.00 y sigma = 0.30\n",
      "#78.78 para C = 1.00 y sigma = 0.30 (entrenamiento)\n",
      "78.27 para C = 3.00 y sigma = 0.30\n",
      "#79.74 para C = 3.00 y sigma = 0.30 (entrenamiento)\n",
      "80.45 para C = 10.00 y sigma = 0.30\n",
      "#81.74 para C = 10.00 y sigma = 0.30 (entrenamiento)\n",
      "81.00 para C = 30.00 y sigma = 0.30\n",
      "#84.15 para C = 30.00 y sigma = 0.30 (entrenamiento)\n",
      "65.36 para C = 0.01 y sigma = 1.00\n",
      "#66.81 para C = 0.01 y sigma = 1.00 (entrenamiento)\n",
      "70.45 para C = 0.03 y sigma = 1.00\n",
      "#71.52 para C = 0.03 y sigma = 1.00 (entrenamiento)\n",
      "72.64 para C = 0.10 y sigma = 1.00\n",
      "#74.44 para C = 0.10 y sigma = 1.00 (entrenamiento)\n",
      "74.45 para C = 0.30 y sigma = 1.00\n",
      "#75.93 para C = 0.30 y sigma = 1.00 (entrenamiento)\n",
      "76.27 para C = 1.00 y sigma = 1.00\n",
      "#77.93 para C = 1.00 y sigma = 1.00 (entrenamiento)\n",
      "76.73 para C = 3.00 y sigma = 1.00\n",
      "#78.48 para C = 3.00 y sigma = 1.00 (entrenamiento)\n",
      "77.09 para C = 10.00 y sigma = 1.00\n",
      "#79.04 para C = 10.00 y sigma = 1.00 (entrenamiento)\n",
      "77.45 para C = 30.00 y sigma = 1.00\n",
      "#79.56 para C = 30.00 y sigma = 1.00 (entrenamiento)\n",
      "65.36 para C = 0.01 y sigma = 3.00\n",
      "#66.81 para C = 0.01 y sigma = 3.00 (entrenamiento)\n",
      "65.36 para C = 0.03 y sigma = 3.00\n",
      "#66.81 para C = 0.03 y sigma = 3.00 (entrenamiento)\n",
      "65.36 para C = 0.10 y sigma = 3.00\n",
      "#66.81 para C = 0.10 y sigma = 3.00 (entrenamiento)\n",
      "71.64 para C = 0.30 y sigma = 3.00\n",
      "#72.56 para C = 0.30 y sigma = 3.00 (entrenamiento)\n",
      "73.36 para C = 1.00 y sigma = 3.00\n",
      "#74.74 para C = 1.00 y sigma = 3.00 (entrenamiento)\n",
      "74.09 para C = 3.00 y sigma = 3.00\n",
      "#75.74 para C = 3.00 y sigma = 3.00 (entrenamiento)\n",
      "75.45 para C = 10.00 y sigma = 3.00\n",
      "#77.15 para C = 10.00 y sigma = 3.00 (entrenamiento)\n",
      "75.91 para C = 30.00 y sigma = 3.00\n",
      "#77.81 para C = 30.00 y sigma = 3.00 (entrenamiento)\n",
      "65.36 para C = 0.01 y sigma = 10.00\n",
      "#66.81 para C = 0.01 y sigma = 10.00 (entrenamiento)\n",
      "65.36 para C = 0.03 y sigma = 10.00\n",
      "#66.81 para C = 0.03 y sigma = 10.00 (entrenamiento)\n",
      "65.36 para C = 0.10 y sigma = 10.00\n",
      "#66.81 para C = 0.10 y sigma = 10.00 (entrenamiento)\n",
      "65.36 para C = 0.30 y sigma = 10.00\n",
      "#66.81 para C = 0.30 y sigma = 10.00 (entrenamiento)\n",
      "65.36 para C = 1.00 y sigma = 10.00\n",
      "#66.81 para C = 1.00 y sigma = 10.00 (entrenamiento)\n",
      "71.91 para C = 3.00 y sigma = 10.00\n",
      "#72.93 para C = 3.00 y sigma = 10.00 (entrenamiento)\n",
      "73.36 para C = 10.00 y sigma = 10.00\n",
      "#74.89 para C = 10.00 y sigma = 10.00 (entrenamiento)\n",
      "74.09 para C = 30.00 y sigma = 10.00\n",
      "#75.52 para C = 30.00 y sigma = 10.00 (entrenamiento)\n",
      "65.36 para C = 0.01 y sigma = 30.00\n",
      "#66.81 para C = 0.01 y sigma = 30.00 (entrenamiento)\n",
      "65.36 para C = 0.03 y sigma = 30.00\n",
      "#66.81 para C = 0.03 y sigma = 30.00 (entrenamiento)\n",
      "65.36 para C = 0.10 y sigma = 30.00\n",
      "#66.81 para C = 0.10 y sigma = 30.00 (entrenamiento)\n",
      "65.36 para C = 0.30 y sigma = 30.00\n",
      "#66.81 para C = 0.30 y sigma = 30.00 (entrenamiento)\n",
      "65.36 para C = 1.00 y sigma = 30.00\n",
      "#66.81 para C = 1.00 y sigma = 30.00 (entrenamiento)\n",
      "65.36 para C = 3.00 y sigma = 30.00\n",
      "#66.81 para C = 3.00 y sigma = 30.00 (entrenamiento)\n",
      "65.45 para C = 10.00 y sigma = 30.00\n",
      "#66.85 para C = 10.00 y sigma = 30.00 (entrenamiento)\n",
      "71.73 para C = 30.00 y sigma = 30.00\n",
      "#72.93 para C = 30.00 y sigma = 30.00 (entrenamiento)\n",
      "Mejor porcentaje de acierto sobre los ejemplos de validaciÃ³n: 81.00\n",
      "[9. 5. 9. ... 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "SVM(2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1./(1. + np.exp(-1. * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pesosAleatorios(Lin, Lout):\n",
    "    ini = 0.12 \n",
    "    theta = np.random.random((Lout,Lin+1))*(2*ini)-ini\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h0(x,theta1,theta2):\n",
    "    z2 = np.matmul(x, theta1.T)\n",
    "    a2 = sigmoide(z2)\n",
    "    a2 = np.hstack((np.ones((a2.shape[0],1)), a2))\n",
    "    \n",
    "    #Capa de salida\n",
    "    z3 = np.matmul(theta2, a2.T)\n",
    "    a3 = sigmoide(z3)\n",
    "    \n",
    "    return a3, a2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coste(xOnes, y2, theta1, theta2, reg):\n",
    "    a3, a2 = h0(xOnes, theta1, theta2)\n",
    "    a = - y2 * np.log(a3).T\n",
    "    b = (1 - y2) * np.log(1 - a3).T\n",
    "    c = np.sum(1. / (xOnes.shape[0]) * (a - b))\n",
    "    coste = c + (reg/(2 * xOnes.shape[0]))*(np.sum(theta1**2) + np.sum(theta2**2))\n",
    "    return coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo funciona para 1 capa oculta\n",
    "def backdrop(params_rn, num_entradas, num_ocultas, num_etiquetas, x, y, reg = 0):\n",
    "    #Desempaqueta los parÃ¡metros\n",
    "    theta1 = np.reshape(params_rn[: num_ocultas * (num_entradas + 1) ],\n",
    "                        (num_ocultas , (num_entradas + 1)))\n",
    "    theta2 = np.reshape(params_rn[num_ocultas * (num_entradas + 1) :],\n",
    "                        (num_etiquetas , (num_ocultas + 1)))\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "\n",
    "    #Genera la matriz de etiquetas.\n",
    "    y2 = np.zeros((len(y), num_etiquetas))\n",
    "    miniy = int(np.min(y))\n",
    "    #Pone los 1 en la matriz de 0\n",
    "    for i in range(len(y)):\n",
    "        y2[i,int(y[i]) - miniy] = 1\n",
    "    \n",
    "    #FORWARD PROPAGATION-------------------------------------------------\n",
    "    a3, a2 = h0(xOnes, theta1, theta2)\n",
    "    a = - y2 * np.log(a3).T\n",
    "    b = (1 - y2) * np.log(1 - a3).T\n",
    "    c = np.sum(1. / (xOnes.shape[0]) * (a - b))\n",
    "    coste = c + (reg/(2 * xOnes.shape[0]))*(np.sum(theta1**2) + np.sum(theta2**2))\n",
    "\n",
    "    #BACKPROPAGATION------------------------------------------------------\n",
    "    delta3 = a3 - y2.T\n",
    "    delta2 = np.matmul(theta2.T, delta3) * (a2.T * (1. - a2.T))\n",
    "    #Copia theta para evitar daÃ±ar la original para vectorizar que\n",
    "    #la primera fila no se modifica al regularizar\n",
    "    theta1c = np.copy(theta1)\n",
    "    theta2c = np.copy(theta2)\n",
    "    theta2c[:,0] = theta2c[:,0] * 0  \n",
    "    theta1c[:,0] = theta1c[:,0] * 0\n",
    "    \n",
    "    #Calcula las theta resultantes, incluyendo la regularizaciÃ³n\n",
    "    triangulo2 = (np.matmul(delta3, a2) / xOnes.shape[0]) \n",
    "    triangulo2 = triangulo2 + (reg/xOnes.shape[0]) * theta2c\n",
    "    triangulo1 = (np.matmul(delta2[1:], xOnes) / xOnes.shape[0]) \n",
    "    triangulo1 = triangulo1 + (reg/xOnes.shape[0]) * theta1c\n",
    "    \n",
    "    return coste, np.concatenate((triangulo1.ravel(),triangulo2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNeural(theta_opt1, theta_opt2, x, y, maxi, mini):\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "    for i in range(xOnes.shape[0]):\n",
    "        salida = h0(xOnes[i,np.newaxis], theta_opt1, theta_opt2)\n",
    "        salida = salida[0].ravel()\n",
    "        print((salida.argmax() + mini) % maxi, \"con un valor h0 de\",  salida.max())\n",
    "        print(\"%i es el valor real\" % int(y[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetwork(reg):\n",
    "    xTraining, yTraining, xVal, yVal, xTest, yTest = loadData()\n",
    "    num_entradas = xTraining.shape[1]\n",
    "    num_ocultas = 25\n",
    "    #print(np.max(yTraining), np.min(yTraining))\n",
    "    \n",
    "    #Utiliza el mÃ­nimo y mÃ¡ximo para crear el nÃºmero de etiquetas,\n",
    "    #Puede variar entre ejecuciones al elegir ejemplos aleatoriamente,\n",
    "    #Ya que tienen una distribuciÃ³ normal\n",
    "    maxi = int(np.max(yTraining))\n",
    "    mini = int(np.min(yTraining))\n",
    "    num_etiquetas = maxi - mini + 1\n",
    "    \n",
    "    #print(num_etiquetas)\n",
    "    \n",
    "    t1 = pesosAleatorios(num_entradas,num_ocultas)\n",
    "    t2 = pesosAleatorios(num_ocultas, num_etiquetas)\n",
    "    params_t = np.vstack((np.reshape(t1, (t1.shape[0]*t1.shape[1],1)),\n",
    "                           np.reshape(t2, (t2.shape[0]*t2.shape[1],1))))\n",
    "    \n",
    "    #Entrena la red neuronal\n",
    "    result = opt.minimize(fun=backdrop, x0=params_t,\n",
    "                          args=(num_entradas, num_ocultas,\n",
    "                                num_etiquetas, xTraining, yTraining, reg),\n",
    "                          method='TNC', jac=True)\n",
    "    \n",
    "    #Desempaqueta la salida del entrenamiento\n",
    "    salida1 = np.reshape(result.x[: num_ocultas * (num_entradas + 1) ], \n",
    "                         (num_ocultas , (num_entradas + 1)))\n",
    "    salida2 = np.reshape(result.x[num_ocultas * (num_entradas + 1) :], \n",
    "                         (num_etiquetas , (num_ocultas + 1)))\n",
    "    \n",
    "    checkNeural(salida1, salida2, xVal[0:20], yVal[0:20], maxi, mini)\n",
    "    \n",
    "    return salida1, salida2, result.fun, maxi, mini\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNetworkDecide():\n",
    "    xTraining, yTraining, xVal, yVal, xTest, yTest = loadData()\n",
    "    num_entradas = xTraining.shape[1]\n",
    "    num_ocultas = 25\n",
    "    #print(np.max(yTraining), np.min(yTraining))\n",
    "    \n",
    "    #Utiliza el mÃ­nimo y mÃ¡ximo para crear el nÃºmero de etiquetas,\n",
    "    #Se utiliza el minimo y mÃ¡ximo entre todos los ejemplos, aunque\n",
    "    #no aparezcan en los de entranamineto\n",
    "    maxi = int(np.max([np.max(yTraining), np.max(yVal), np.max(yTest)]))\n",
    "    mini = int(np.min([np.min(yTraining), np.min(yVal), np.min(yTest)]))\n",
    "    print(maxi,mini)\n",
    "    num_etiquetas = maxi - mini + 1\n",
    "    \n",
    "    #print(num_etiquetas)\n",
    "    \n",
    "    xValOnes = np.hstack((np.ones((xVal.shape[0],1)), xVal))\n",
    "\n",
    "    #Genera la matriz de etiquetas.\n",
    "    yVal2 = np.zeros((len(yVal), num_etiquetas))\n",
    "    #Pone los 1 en la matriz de 0\n",
    "    for i in range(len(yVal)):\n",
    "        yVal2[i,int(yVal[i]) - mini] = 1\n",
    "    \n",
    "    reg = np.array([0.001, 0.003, 0.007, 0.01, 0.03, 0.07, \n",
    "                    0.1, 0.3, 0.7, 1, 3, 7, 10, 30])\n",
    "    #Entrena la red neuronal\n",
    "    for i in reg:\n",
    "        t1 = pesosAleatorios(num_entradas,num_ocultas)\n",
    "        t2 = pesosAleatorios(num_ocultas, num_etiquetas)\n",
    "        params_t = np.vstack((np.reshape(t1, (t1.shape[0]*t1.shape[1],1)),\n",
    "                            np.reshape(t2, (t2.shape[0]*t2.shape[1],1))))\n",
    "        result = opt.minimize(fun=backdrop, x0=params_t,\n",
    "                              args=(num_entradas, num_ocultas,\n",
    "                                    num_etiquetas, xTraining, yTraining, i),\n",
    "                              method='TNC', jac=True)\n",
    "    \n",
    "    #Desempaqueta la salida del entrenamiento\n",
    "        salida1 = np.reshape(result.x[: num_ocultas * (num_entradas + 1) ], \n",
    "                             (num_ocultas , (num_entradas + 1)))\n",
    "        salida2 = np.reshape(result.x[num_ocultas * (num_entradas + 1) :], \n",
    "                             (num_etiquetas , (num_ocultas + 1)))\n",
    "        \n",
    "        cost = coste(xValOnes, yVal2, salida1, salida2, i)\n",
    "        print(\"%.5f para reg = %.3f\" % (cost, i))\n",
    "    \n",
    "    checkNeural(salida1, salida2, xVal[0:20], yVal[0:20], maxi, mini)\n",
    "    \n",
    "    return salida1, salida2, result.fun, maxi, mini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 con un valor h0 de 0.2274800150759529\n",
      "11 es el valor real\n",
      "9 con un valor h0 de 0.22051240617581153\n",
      "9 es el valor real\n",
      "8 con un valor h0 de 0.3180418290234178\n",
      "10 es el valor real\n",
      "8 con un valor h0 de 0.3111725401297824\n",
      "8 es el valor real\n",
      "10 con un valor h0 de 0.324781858972899\n",
      "10 es el valor real\n",
      "10 con un valor h0 de 0.2477256272212695\n",
      "9 es el valor real\n",
      "10 con un valor h0 de 0.3259515734014004\n",
      "14 es el valor real\n",
      "10 con un valor h0 de 0.3091391604289531\n",
      "10 es el valor real\n",
      "11 con un valor h0 de 0.4004792007798561\n",
      "12 es el valor real\n",
      "7 con un valor h0 de 0.4822776145967882\n",
      "7 es el valor real\n",
      "13 con un valor h0 de 0.15666870588447213\n",
      "19 es el valor real\n",
      "9 con un valor h0 de 0.3125544370853389\n",
      "8 es el valor real\n",
      "7 con un valor h0 de 0.44461343834650674\n",
      "8 es el valor real\n",
      "10 con un valor h0 de 0.16600737314360905\n",
      "9 es el valor real\n",
      "9 con un valor h0 de 0.28511334470408567\n",
      "7 es el valor real\n",
      "13 con un valor h0 de 0.38654181294578643\n",
      "21 es el valor real\n",
      "9 con un valor h0 de 0.38119580963881133\n",
      "8 es el valor real\n",
      "10 con un valor h0 de 0.3164420771406788\n",
      "11 es el valor real\n",
      "9 con un valor h0 de 0.2770225074674208\n",
      "8 es el valor real\n",
      "9 con un valor h0 de 0.31822206195836383\n",
      "11 es el valor real\n",
      "COSTE 2.7193697062200815\n"
     ]
    }
   ],
   "source": [
    "theta_opt1, theta_opt2, coste_opt, maxi, mini = neuralNetwork(0)\n",
    "print(\"COSTE\", coste_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Miguel\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33351 para reg = 0.001\n",
      "3.29173 para reg = 0.003\n",
      "3.63243 para reg = 0.007\n",
      "3.35247 para reg = 0.010\n",
      "3.44786 para reg = 0.030\n",
      "3.39373 para reg = 0.070\n",
      "3.40293 para reg = 0.100\n",
      "3.45199 para reg = 0.300\n",
      "3.55736 para reg = 0.700\n",
      "3.57885 para reg = 1.000\n",
      "3.71293 para reg = 3.000\n",
      "4.00940 para reg = 7.000\n",
      "4.09149 para reg = 10.000\n",
      "4.30155 para reg = 30.000\n",
      "8 con un valor h0 de 0.19585425775863133\n",
      "5 es el valor real\n",
      "8 con un valor h0 de 0.190471916986668\n",
      "8 es el valor real\n",
      "8 con un valor h0 de 0.18821883643389786\n",
      "8 es el valor real\n",
      "8 con un valor h0 de 0.18286584031703096\n",
      "14 es el valor real\n",
      "8 con un valor h0 de 0.1907230856600843\n",
      "6 es el valor real\n",
      "8 con un valor h0 de 0.17783703903692513\n",
      "20 es el valor real\n",
      "8 con un valor h0 de 0.17781926321650035\n",
      "13 es el valor real\n",
      "8 con un valor h0 de 0.18406288353531125\n",
      "8 es el valor real\n",
      "8 con un valor h0 de 0.17725006167473883\n",
      "9 es el valor real\n",
      "8 con un valor h0 de 0.18530418759580777\n",
      "8 es el valor real\n",
      "8 con un valor h0 de 0.1709574698780437\n",
      "14 es el valor real\n",
      "8 con un valor h0 de 0.17248675015400883\n",
      "8 es el valor real\n",
      "8 con un valor h0 de 0.1666174516687852\n",
      "23 es el valor real\n",
      "8 con un valor h0 de 0.17983797590742234\n",
      "8 es el valor real\n",
      "8 con un valor h0 de 0.17104979902391218\n",
      "9 es el valor real\n",
      "8 con un valor h0 de 0.1728025581569787\n",
      "18 es el valor real\n",
      "8 con un valor h0 de 0.16818375907823696\n",
      "12 es el valor real\n",
      "8 con un valor h0 de 0.18702105236744537\n",
      "8 es el valor real\n",
      "8 con un valor h0 de 0.17584201613861364\n",
      "14 es el valor real\n",
      "8 con un valor h0 de 0.16931680410630542\n",
      "10 es el valor real\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.59843552, -0.01788844,  0.24247536,  0.1053231 ,  0.03380003,\n",
       "          0.16193686,  0.13598096,  0.00676424,  0.05815886],\n",
       "        [ 0.5577679 ,  0.05370242,  0.20714091,  0.15268207,  0.03904425,\n",
       "          0.32802722,  0.20172468,  0.09618347,  0.12377531],\n",
       "        [ 0.5332895 ,  0.03748576,  0.14951144,  0.19983278,  0.00525763,\n",
       "          0.33082754,  0.15249791,  0.05896006,  0.07854654],\n",
       "        [ 0.53411759,  0.05201045,  0.20644912,  0.13989592,  0.04290564,\n",
       "          0.43472133,  0.13297316,  0.03414679,  0.15547437],\n",
       "        [ 0.52783991, -0.03766261,  0.20991159,  0.1652543 ,  0.07363646,\n",
       "          0.23265456,  0.11983924,  0.0322619 ,  0.07455964],\n",
       "        [ 0.68416079,  0.05708981,  0.20325967,  0.13128917,  0.00952217,\n",
       "          0.33188429,  0.07222332,  0.00791247,  0.11845834],\n",
       "        [ 0.77102425,  0.066856  ,  0.1859344 ,  0.11197695,  0.04035744,\n",
       "          0.22758306,  0.05475554,  0.03423485,  0.0574373 ],\n",
       "        [ 0.63388654,  0.01295431,  0.20844049,  0.21594901,  0.04574232,\n",
       "          0.28878488,  0.1116731 ,  0.04731135,  0.06332338],\n",
       "        [ 0.61363946,  0.00903719,  0.16646506,  0.16819901,  0.02884706,\n",
       "          0.1515672 ,  0.14347721,  0.06734933,  0.00476428],\n",
       "        [ 0.63461665, -0.00188962,  0.17679248,  0.18292405,  0.05200182,\n",
       "          0.25025839,  0.08526714,  0.03533434,  0.02903406],\n",
       "        [ 0.4854477 , -0.02464396,  0.18580788,  0.14225393,  0.02751706,\n",
       "          0.19985442,  0.14531518,  0.03836629,  0.02112816],\n",
       "        [ 0.51702287,  0.04125468,  0.20587329,  0.11762517,  0.03642911,\n",
       "          0.37337346,  0.10153226,  0.13314882,  0.12676806],\n",
       "        [ 0.70155244, -0.01044853,  0.22745843,  0.15034143,  0.04178278,\n",
       "          0.27855162,  0.1153697 ,  0.03662459,  0.08338839],\n",
       "        [ 0.72291723,  0.01175477,  0.22576103,  0.10363907,  0.10341016,\n",
       "          0.20199381,  0.16673806,  0.06674633,  0.09970946],\n",
       "        [ 0.70358778,  0.04334958,  0.15876481,  0.14179348,  0.0590017 ,\n",
       "          0.22685959,  0.16601526,  0.08710175,  0.0340255 ],\n",
       "        [ 0.58397439, -0.02325406,  0.14519042,  0.10204268,  0.09501405,\n",
       "          0.20874377,  0.13948942,  0.04384504,  0.02800331],\n",
       "        [ 0.56821174,  0.0434394 ,  0.15212525,  0.09434995,  0.08474486,\n",
       "          0.18902338,  0.08890825,  0.02318091,  0.048842  ],\n",
       "        [ 0.57762992,  0.00169231,  0.18982745,  0.21199846,  0.06815608,\n",
       "          0.26987117,  0.09163433,  0.03972302,  0.08629806],\n",
       "        [ 0.55059055,  0.05093393,  0.22547453,  0.14425458,  0.03695846,\n",
       "          0.33859064,  0.08851715,  0.03187301,  0.09707455],\n",
       "        [ 0.63220946,  0.05506688,  0.20895752,  0.11558622,  0.07176725,\n",
       "          0.26368152,  0.07384766,  0.11879049,  0.04329384],\n",
       "        [ 0.70264378, -0.00270054,  0.16516278,  0.21994921,  0.0679702 ,\n",
       "          0.35318445,  0.08560296,  0.02422758,  0.07176781],\n",
       "        [ 0.75464346,  0.04609557,  0.21426991,  0.11518155,  0.03544732,\n",
       "          0.27671625,  0.125726  ,  0.01021783,  0.09371294],\n",
       "        [ 0.63148494,  0.00092106,  0.167268  ,  0.12041209,  0.03732727,\n",
       "          0.19342801,  0.05615571,  0.06911627,  0.00877164],\n",
       "        [ 0.55228321,  0.05406075,  0.22760801,  0.19711723,  0.04274662,\n",
       "          0.25825965,  0.17901113,  0.06142067,  0.04479899],\n",
       "        [ 0.56319824,  0.03070412,  0.27606442,  0.11983806,  0.01485186,\n",
       "          0.34178097,  0.09112378,  0.06369956,  0.08498035]]),\n",
       " array([[-0.53992883, -0.21697406, -0.27784927, -0.22138698, -0.32207707,\n",
       "         -0.32141372, -0.34580441, -0.24804634, -0.34200392, -0.21897493,\n",
       "         -0.22322182, -0.20425351, -0.23656061, -0.23860529, -0.31646876,\n",
       "         -0.2304887 , -0.21119144, -0.20728834, -0.30894935, -0.24118128,\n",
       "         -0.22656563, -0.24378959, -0.33765428, -0.29367738, -0.3242785 ,\n",
       "         -0.2343149 ],\n",
       "        [-0.42720022, -0.18560511, -0.31491921, -0.27199886, -0.28632954,\n",
       "         -0.24967107, -0.31762672, -0.30922724, -0.21061065, -0.19729372,\n",
       "         -0.1853688 , -0.2109314 , -0.20628659, -0.23061726, -0.19928109,\n",
       "         -0.27464482, -0.22612958, -0.28045944, -0.28462814, -0.24231631,\n",
       "         -0.21580155, -0.31466868, -0.21258747, -0.20698064, -0.2138085 ,\n",
       "         -0.23889597],\n",
       "        [-0.29387784, -0.16863872, -0.21376818, -0.1618347 , -0.26824214,\n",
       "         -0.22345355, -0.26582804, -0.19839328, -0.2460866 , -0.23297118,\n",
       "         -0.25940024, -0.13947883, -0.24307237, -0.21556464, -0.17204533,\n",
       "         -0.23065405, -0.15936379, -0.15761566, -0.2661688 , -0.25199794,\n",
       "         -0.25405807, -0.28503079, -0.22073373, -0.19602067, -0.16085947,\n",
       "         -0.2149512 ],\n",
       "        [-0.37936651, -0.21356646, -0.18061917, -0.17504672, -0.27374418,\n",
       "         -0.14206867, -0.20911229, -0.22716382, -0.2376349 , -0.17906388,\n",
       "         -0.13358707, -0.11567706, -0.17971977, -0.14967753, -0.16785068,\n",
       "         -0.15593314, -0.18181904, -0.11789911, -0.13264914, -0.2319371 ,\n",
       "         -0.1791639 , -0.20279649, -0.16567658, -0.16397754, -0.15275884,\n",
       "         -0.26070077],\n",
       "        [ 0.0100084 , -0.09969358, -0.21477387, -0.14414885, -0.25349611,\n",
       "         -0.10946451, -0.14129982, -0.06864928, -0.14126108, -0.08875511,\n",
       "         -0.17343231, -0.15485994, -0.22897936, -0.12578488, -0.09970561,\n",
       "         -0.15149166, -0.08586905, -0.15038641, -0.16890992, -0.13500971,\n",
       "         -0.11965438, -0.13944751, -0.18102288, -0.09094107, -0.11114346,\n",
       "         -0.21757196],\n",
       "        [ 0.01906104, -0.11220122, -0.16048622, -0.17989797, -0.18885411,\n",
       "         -0.17650527, -0.10176517, -0.14621524, -0.09536264, -0.09387486,\n",
       "         -0.12191173, -0.06102228, -0.12909308, -0.1209906 , -0.09862152,\n",
       "         -0.11538987, -0.13898105, -0.07776491, -0.19328509, -0.17145143,\n",
       "         -0.17080413, -0.15428513, -0.08801773, -0.06469825, -0.11333926,\n",
       "         -0.11121294],\n",
       "        [-0.0572231 , -0.09883016, -0.08100553, -0.11513771, -0.11928023,\n",
       "         -0.10130632, -0.06429731, -0.06144221, -0.06518782, -0.0500339 ,\n",
       "         -0.09097386, -0.05314289, -0.12852878, -0.14241765, -0.08543212,\n",
       "         -0.08389263, -0.08403407, -0.12341551, -0.07862024, -0.13734648,\n",
       "         -0.07323241, -0.111675  , -0.0590233 , -0.12551575, -0.09953969,\n",
       "         -0.12909017],\n",
       "        [-0.18241547, -0.06031482, -0.01301807, -0.05396352, -0.01019797,\n",
       "         -0.0500312 , -0.12795221, -0.05961112, -0.04534311, -0.12223348,\n",
       "         -0.08353366, -0.02342393, -0.03697047, -0.10124413, -0.09990668,\n",
       "         -0.09276288, -0.1130818 , -0.0375509 , -0.10743391, -0.09222854,\n",
       "         -0.0440792 , -0.07698116, -0.12416671, -0.1374983 , -0.04194578,\n",
       "         -0.07033795],\n",
       "        [-0.31165984, -0.15185666, -0.0088426 , -0.00776111,  0.01610894,\n",
       "         -0.06570101, -0.05288274, -0.14690511, -0.0269667 , -0.13746053,\n",
       "         -0.09614975, -0.05666624,  0.00156044, -0.04403462, -0.07573874,\n",
       "         -0.06039685, -0.11829853, -0.13746534, -0.12530665, -0.0577594 ,\n",
       "         -0.04290355, -0.03327475, -0.13674278, -0.13530216, -0.06018556,\n",
       "         -0.07960945],\n",
       "        [-0.50860568, -0.14534457, -0.07380478, -0.04504524,  0.00904399,\n",
       "         -0.12228708, -0.02969655, -0.12598515, -0.1162316 , -0.13752239,\n",
       "         -0.07034122, -0.04780731, -0.03109562, -0.06307842, -0.0378908 ,\n",
       "         -0.13822372, -0.10536258, -0.15596822, -0.02181189, -0.09538628,\n",
       "         -0.1349883 , -0.06161252, -0.03487668, -0.06874866,  0.00137605,\n",
       "         -0.03786593],\n",
       "        [-0.32752663, -0.18226858, -0.10023049, -0.16711635, -0.14825069,\n",
       "         -0.08144092, -0.11007877, -0.19942325, -0.14263698, -0.16489564,\n",
       "         -0.10598789, -0.08472651, -0.06046777, -0.17444618, -0.14135743,\n",
       "         -0.10213974, -0.15768925, -0.08219974, -0.07307123, -0.07422079,\n",
       "         -0.15757644, -0.14490718, -0.09815916, -0.10082156, -0.07476613,\n",
       "         -0.08619702],\n",
       "        [-0.28529424, -0.10976678, -0.11735394, -0.13291522, -0.15970842,\n",
       "         -0.08481345, -0.19519327, -0.14506136, -0.14279774, -0.17792682,\n",
       "         -0.14801028, -0.1763265 , -0.1053129 , -0.10719873, -0.2015395 ,\n",
       "         -0.11942945, -0.11923142, -0.15226481, -0.15899033, -0.10434135,\n",
       "         -0.15087829, -0.09840978, -0.19254033, -0.15865354, -0.19640278,\n",
       "         -0.1299465 ],\n",
       "        [-0.45047823, -0.12400528, -0.18087731, -0.22461406, -0.13751859,\n",
       "         -0.11697627, -0.18222618, -0.13907223, -0.17495633, -0.14097485,\n",
       "         -0.11972313, -0.15085379, -0.15588543, -0.19518879, -0.20873521,\n",
       "         -0.16344848, -0.2062236 , -0.20116778, -0.19202403, -0.1359698 ,\n",
       "         -0.13295895, -0.22179143, -0.1465133 , -0.12600197, -0.16680723,\n",
       "         -0.11416717],\n",
       "        [-0.38309747, -0.15302721, -0.15445682, -0.24307218, -0.18382963,\n",
       "         -0.12835486, -0.18325925, -0.14970506, -0.1469071 , -0.17777743,\n",
       "         -0.16820776, -0.14037644, -0.20548658, -0.21706195, -0.24195625,\n",
       "         -0.14655559, -0.20192204, -0.16047819, -0.22635119, -0.18453518,\n",
       "         -0.22112264, -0.16646367, -0.23865006, -0.13701013, -0.19748734,\n",
       "         -0.24226039],\n",
       "        [-0.56056551, -0.1492151 , -0.17041151, -0.24611364, -0.16164984,\n",
       "         -0.16728068, -0.23936257, -0.16930713, -0.1846    , -0.20333928,\n",
       "         -0.17518447, -0.16723989, -0.14248623, -0.1736696 , -0.17189513,\n",
       "         -0.26998106, -0.17503744, -0.24742152, -0.18056998, -0.17329341,\n",
       "         -0.16775598, -0.19555623, -0.24009008, -0.1586548 , -0.21013538,\n",
       "         -0.15111755],\n",
       "        [-0.55364442, -0.25830951, -0.18848959, -0.1949763 , -0.17648085,\n",
       "         -0.16289959, -0.21497566, -0.17367309, -0.26798565, -0.18191639,\n",
       "         -0.18414894, -0.16392539, -0.15843336, -0.25476072, -0.22805395,\n",
       "         -0.17095315, -0.19816949, -0.16925293, -0.22634943, -0.26436952,\n",
       "         -0.16331767, -0.27304118, -0.20160334, -0.22884478, -0.21476514,\n",
       "         -0.19669556],\n",
       "        [-0.42772174, -0.284156  , -0.17821151, -0.17161568, -0.22110177,\n",
       "         -0.18581513, -0.2326421 , -0.28171067, -0.28021135, -0.19148916,\n",
       "         -0.24351538, -0.22727877, -0.21622198, -0.28863228, -0.23185761,\n",
       "         -0.1912431 , -0.18367422, -0.17215287, -0.1682664 , -0.2808096 ,\n",
       "         -0.19347123, -0.2529332 , -0.27513847, -0.20417303, -0.23714752,\n",
       "         -0.23487126],\n",
       "        [-0.46524669, -0.24930837, -0.30208692, -0.20070607, -0.19456852,\n",
       "         -0.18777781, -0.26578078, -0.29180182, -0.20979845, -0.20417753,\n",
       "         -0.1913656 , -0.24735506, -0.2086287 , -0.19921874, -0.22175786,\n",
       "         -0.20095804, -0.17928652, -0.24123046, -0.19580801, -0.20519235,\n",
       "         -0.22583493, -0.31848699, -0.28661667, -0.18036486, -0.26863527,\n",
       "         -0.28518569],\n",
       "        [-0.65229471, -0.19413833, -0.19383855, -0.28255154, -0.19401002,\n",
       "         -0.19476477, -0.21205593, -0.22426553, -0.2864111 , -0.25392654,\n",
       "         -0.29210388, -0.19147251, -0.25568001, -0.20281711, -0.22615856,\n",
       "         -0.20869698, -0.18351529, -0.28853505, -0.25963045, -0.19994194,\n",
       "         -0.20909825, -0.21296031, -0.22288329, -0.19471039, -0.20583189,\n",
       "         -0.19954496],\n",
       "        [-0.45405955, -0.18737124, -0.30769318, -0.19151329, -0.19028005,\n",
       "         -0.26280023, -0.20445721, -0.21671553, -0.29716831, -0.19680234,\n",
       "         -0.28542772, -0.25532472, -0.27291904, -0.20057691, -0.21353016,\n",
       "         -0.22013414, -0.25602278, -0.22978712, -0.24399758, -0.21199919,\n",
       "         -0.2716395 , -0.27794167, -0.28583652, -0.29269023, -0.19275443,\n",
       "         -0.29804422],\n",
       "        [-0.47913395, -0.26636695, -0.24679179, -0.19850767, -0.21192934,\n",
       "         -0.3056794 , -0.23721799, -0.22949528, -0.22282355, -0.2217106 ,\n",
       "         -0.30522474, -0.19645183, -0.29634532, -0.2235994 , -0.29060378,\n",
       "         -0.29711153, -0.19273243, -0.19408064, -0.22251741, -0.30753137,\n",
       "         -0.27452265, -0.32059678, -0.30690164, -0.19474838, -0.27652103,\n",
       "         -0.30783041],\n",
       "        [-0.46936637, -0.1965012 , -0.21806466, -0.20262363, -0.30824163,\n",
       "         -0.29304871, -0.29639047, -0.28338602, -0.22103225, -0.20582166,\n",
       "         -0.26698912, -0.2526639 , -0.29397205, -0.21580085, -0.22989524,\n",
       "         -0.2949724 , -0.22063862, -0.23185382, -0.29243898, -0.22623507,\n",
       "         -0.30021129, -0.22670777, -0.23447066, -0.2062436 , -0.22662373,\n",
       "         -0.25893486],\n",
       "        [-0.52796941, -0.23566691, -0.29268455, -0.29077072, -0.246364  ,\n",
       "         -0.21362355, -0.2817242 , -0.24051454, -0.25614145, -0.21983795,\n",
       "         -0.23986524, -0.27809898, -0.24206013, -0.24145311, -0.23595781,\n",
       "         -0.27328485, -0.29364166, -0.22469415, -0.24118067, -0.28448981,\n",
       "         -0.33741709, -0.25665092, -0.24622197, -0.31755886, -0.32315471,\n",
       "         -0.232199  ],\n",
       "        [-0.52291576, -0.22968502, -0.31225611, -0.23669505, -0.26344622,\n",
       "         -0.28713964, -0.23891952, -0.32795107, -0.23793432, -0.2188655 ,\n",
       "         -0.22669035, -0.2688086 , -0.31217283, -0.34161752, -0.22999421,\n",
       "         -0.23866324, -0.23298705, -0.28337507, -0.22595649, -0.21671953,\n",
       "         -0.27502871, -0.25183418, -0.28670672, -0.24230427, -0.24165468,\n",
       "         -0.24397682],\n",
       "        [-0.54406061, -0.28391499, -0.23629605, -0.28323692, -0.32047721,\n",
       "         -0.23120169, -0.23044557, -0.22666345, -0.22651661, -0.32076282,\n",
       "         -0.28249298, -0.24430834, -0.22389639, -0.31685124, -0.32825517,\n",
       "         -0.27390617, -0.30843847, -0.2192352 , -0.20966877, -0.30264378,\n",
       "         -0.30490702, -0.25247476, -0.2391274 , -0.20395189, -0.2147835 ,\n",
       "         -0.27855928],\n",
       "        [-0.53484463, -0.22574869, -0.2845092 , -0.30670445, -0.23965379,\n",
       "         -0.21200211, -0.33952982, -0.2429449 , -0.26572359, -0.21629042,\n",
       "         -0.30750687, -0.21015484, -0.22210847, -0.23461466, -0.33256022,\n",
       "         -0.33078048, -0.28156591, -0.20482298, -0.21185652, -0.26078805,\n",
       "         -0.26628602, -0.25155676, -0.29797848, -0.31052611, -0.23525859,\n",
       "         -0.23066257],\n",
       "        [-0.51597756, -0.25102313, -0.32367162, -0.2071136 , -0.32438507,\n",
       "         -0.28909933, -0.21428992, -0.30904121, -0.30171485, -0.31490216,\n",
       "         -0.23407988, -0.1892207 , -0.30101637, -0.29426365, -0.21219881,\n",
       "         -0.22620111, -0.29070761, -0.29184238, -0.21843073, -0.20564562,\n",
       "         -0.28145043, -0.24465528, -0.23292594, -0.21274297, -0.25693811,\n",
       "         -0.26266386],\n",
       "        [-0.71618814, -0.21412144, -0.27993579, -0.19783783, -0.20894497,\n",
       "         -0.25868066, -0.23015614, -0.27771703, -0.23200825, -0.31056021,\n",
       "         -0.28798982, -0.2411167 , -0.27437341, -0.32823454, -0.30555534,\n",
       "         -0.22033594, -0.19412105, -0.21737217, -0.26295729, -0.21212845,\n",
       "         -0.21073468, -0.31640485, -0.2279562 , -0.19347185, -0.29882868,\n",
       "         -0.22454725],\n",
       "        [-0.5394116 , -0.23523134, -0.24103145, -0.2221775 , -0.33261008,\n",
       "         -0.21213916, -0.27602391, -0.2350512 , -0.3253136 , -0.23777895,\n",
       "         -0.27299148, -0.21036703, -0.23639972, -0.35210858, -0.25850752,\n",
       "         -0.28447556, -0.31919567, -0.24554924, -0.28317311, -0.22363589,\n",
       "         -0.30608075, -0.2456347 , -0.25012315, -0.24649841, -0.23599904,\n",
       "         -0.30313786]]),\n",
       " 3.737972292743738,\n",
       " 29,\n",
       " 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralNetworkDecide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
