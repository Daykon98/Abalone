{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.optimize as opt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coge el archivo abalone.txt y sustituye F M e I\n",
    "#por valores numéricos que pueda leer luego\n",
    "#Almacena la sustitución en abaloneProcessed.txt\n",
    "def preprocess():\n",
    "    f = open(\"abalone.txt\", 'r')\n",
    "    o = open(\"abaloneProcessed.txt\", 'w')\n",
    "    c = f.read(1)\n",
    "    while True:\n",
    "        if not c:\n",
    "            break\n",
    "        if c == 'M':\n",
    "            o.write('-1')\n",
    "        elif c == 'F':\n",
    "            o.write('1')\n",
    "        elif c == 'I':\n",
    "            o.write('0')\n",
    "        else:\n",
    "            o.write(c)\n",
    "        c = f.read(1)\n",
    "    f.close()\n",
    "    o.close()\n",
    "    \n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precondición \n",
    "#0 < Numtraining < 3800; 0 < components < 9; 1 < groupsize < 30\n",
    "#Carga los datos aleatoriamente\n",
    "def loadDataShuffled(decompose=False, components=2, shrinky=False, \n",
    "                     groupSize=2, numTraining = 3000):\n",
    "    data = np.genfromtxt('abaloneProcessed.txt', delimiter=',')\n",
    "    \n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    #Si se quiere reducir los parámetros con PCA\n",
    "    if decompose == True:\n",
    "        pca = decomposition.PCA(n_components = components)\n",
    "        pca.fit(x)\n",
    "        x = pca.transform(x)\n",
    "    \n",
    "    #Si se quiere agrupar la y en grupos\n",
    "    if shrinky == True:\n",
    "        y = y // groupSize\n",
    "    \n",
    "    join = np.hstack((x, np.c_[y]))\n",
    "    np.random.shuffle(join)\n",
    "    \n",
    "    #Se vuelven a separar tras barajearse\n",
    "    xShuffled = join[:,:-1]\n",
    "    yShuffled = join[:,-1]\n",
    "    \n",
    "    #numTraining decide cuantos ejemplos hay para entrenamiento,\n",
    "    #y cuantos hay para validación (3800 - numTraining)\n",
    "    xTraining = xShuffled[:numTraining]\n",
    "    yTraining = yShuffled[:numTraining]\n",
    "    xVal = xShuffled[numTraining:3800]\n",
    "    yVal = yShuffled[numTraining:3800]\n",
    "    xTest = xShuffled[3800:]\n",
    "    yTest = yShuffled[3800:]\n",
    "    \n",
    "    return xTraining, yTraining, xVal, yVal, xTest, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga para entrenar las muestras distintas a lo normal,\n",
    "#y para validar las normales.\n",
    "def loadDataTrainOdd():\n",
    "    data = np.genfromtxt('abaloneProcessed.txt', delimiter=',')\n",
    "    \n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    xTraining = np.empty((0, x.shape[1]))\n",
    "    yTraining = np.array([])\n",
    "    xVal = np.empty((0, x.shape[1]))\n",
    "    yVal = np.array([])\n",
    "    xTest = np.empty((0, x.shape[1]))\n",
    "    yTest = np.array([])\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        #Valores extraidos a partir de la desviación \n",
    "        #típcia y la media de y\n",
    "        if y[i] < 5 or y[i] > 15:\n",
    "            xTraining = np.vstack((xTraining, x[i]))\n",
    "            yTraining = np.append(yTraining, y[i])\n",
    "        elif random.randint(0,1) == 1:\n",
    "            xVal = np.vstack((xVal, x[i]))\n",
    "            yVal = np.append(yVal, y[i])\n",
    "        else: \n",
    "            xTest = np.vstack((xTest, x[i]))\n",
    "            yTest = np.append(yTest, y[i])\n",
    "    return xTraining, yTraining, xVal, yVal, xTest, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga para entrenar las muestras normales,\n",
    "#y para validar las raras.\n",
    "def loadDataTrainNormal():\n",
    "    data = np.genfromtxt('abaloneProcessed.txt', delimiter=',')\n",
    "    \n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    print(np.mean(y), np.std(y))\n",
    "    \n",
    "    xTraining = np.empty((0, x.shape[1]))\n",
    "    yTraining = np.array([])\n",
    "    xVal = np.empty((0, x.shape[1]))\n",
    "    yVal = np.array([])\n",
    "    xTest = np.empty((0, x.shape[1]))\n",
    "    yTest = np.array([])\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        \n",
    "        if y[i] >= 5 and y[i] <= 15:\n",
    "            xTraining = np.vstack((xTraining, x[i]))\n",
    "            yTraining = np.append(yTraining, y[i])\n",
    "        elif random.randint(0,1) == 1:\n",
    "            xVal = np.vstack((xVal, x[i]))\n",
    "            yVal = np.append(yVal, y[i])\n",
    "        else: \n",
    "            xTest = np.vstack((xTest, x[i]))\n",
    "            yTest = np.append(yTest, y[i])\n",
    "    return xTraining, yTraining, xVal, yVal, xTest, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muestra en un gráfico la distribución del número de ejemplos \n",
    "#respecto al número de anillos.\n",
    "def showDistribution():\n",
    "    data = np.genfromtxt('abaloneProcessed.txt', delimiter=',')\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    distinctY = np.unique(y)\n",
    "    count = np.zeros_like(distinctY)\n",
    "    k = 0\n",
    "    for i in distinctY:\n",
    "        count[k] = np.sum(y == i)\n",
    "        k = k + 1\n",
    "    print(count)\n",
    "    plt.figure()\n",
    "    plt.title(\"Distribution of examples\")\n",
    "    plt.ylabel(\"Number of examples\")\n",
    "    plt.xlabel(\"Number of rings\")\n",
    "    plt.bar(distinctY, count, color=\"cornflowerblue\")\n",
    "    plt.savefig(\"graph/distribution\")\n",
    "\n",
    "showDistribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muestra la correlación de un atributo con\n",
    "#el número de anillos\n",
    "def showCorrelation(attribute):\n",
    "    data = np.genfromtxt('abaloneProcessed.txt', delimiter=',')\n",
    "    y = data[:,-1]\n",
    "    x = data[:,:-1]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(x[:,attribute], y, \"x\", c=\"tomato\")\n",
    "    plt.ylabel(\"Number of Rings\")\n",
    "    plt.title(\"Correlation with shell weight\")\n",
    "    plt.xlabel(\"Shell Weight (after being dried) (g)\")\n",
    "    plt.savefig(\"graph/ShellWeight\")\n",
    "    \n",
    "showCorrelation(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asume que esta hecho con -1 Male, 0 Infant, 1 Female\n",
    "#Muestra cuantos ejemplos hay para cada sexo\n",
    "def showExamplesEachSex():\n",
    "    data = np.genfromtxt('abaloneProcessed.txt', delimiter=',')\n",
    "    y = data[:,-1]\n",
    "    x = data[:,:-1]\n",
    "    \n",
    "    sex = np.array([-1, 0, 1])\n",
    "    number = np.zeros_like(sex)\n",
    "    number[0] = np.sum(x[:,0] == -1)\n",
    "    number[1] = np.sum(x[:,0] == 0)\n",
    "    number[2] = np.sum(x[:,0] == 1)\n",
    "    plt.figure()\n",
    "    plt.title(\"Distribution for sex\")\n",
    "    plt.ylabel(\"Number of examples\")\n",
    "    plt.xlabel(\"Sex (-1 = Male; 0 = Infant; 1 = Female)\")\n",
    "    plt.bar(sex, number, color=\"cornflowerblue\")\n",
    "    plt.savefig(\"graph/distributionSex\")\n",
    "\n",
    "showExamplesEachSex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porcentaje de correctos para la SVM, teniendo en cuenta\n",
    "#que consideramos correctos los que predigan +- rango\n",
    "#del valor correcto\n",
    "def correctPercentage(svm, x, y, rango):\n",
    "    array = svm.predict(x)\n",
    "    cmp = (np.abs(array - y) <= rango) \n",
    "    return np.sum(cmp)/len(y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de error, hace que los que se alejen demasiado \n",
    "#lo aumenten exponencialmente más.\n",
    "def errorAmmountSVM(svm, x, y):\n",
    "    array = svm.predict(x)\n",
    "    return np.sum(np.abs(array - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pone ejemplos, predicciones hechas por la svm y \n",
    "#el valor real.\n",
    "def printExamplesSVM(svm, x, y):\n",
    "    array = svm.predict(x)\n",
    "    k = 0\n",
    "    for i in array:\n",
    "        print(\"Valores de x: \", x[k])\n",
    "        print(\"El valor predicho es: %i\" % i)\n",
    "        print(\"El valor real es: %.0f\" % y[k])\n",
    "        k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementación de una SVM, dibujando variós gráficos, incluida\n",
    "#uno en 3d sobre la efectividad de C y sigma \n",
    "def SVM(rango): \n",
    "    xTraining,yTraining,xVal,yVal,xTest,yTest = loadDataShuffled(numTraining=3000)\n",
    "    bestvalue = -1\n",
    "    nums = np.array([0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30])\n",
    "    k = 0\n",
    "    bestValuesMatrix = np.array([])\n",
    "    bestValuesMatrixT = np.array([])\n",
    "\n",
    "    #Prueba para todos los sigmas con todos los C\n",
    "    for sigma in nums:\n",
    "        plt.figure()\n",
    "        arrayPer = np.array([])\n",
    "        arrayPerTraining = np.array([])\n",
    "        bestValuesArray = np.array([])\n",
    "        \n",
    "        plt.xlabel(\"C\")\n",
    "        plt.ylabel(\"Correct percentage (error margin = %i)\" % rango)\n",
    "        plt.title(\"Sigma = %.2f\" % sigma)\n",
    "        for c in nums:\n",
    "            svm = SVC(kernel='rbf', C=c ,gamma=1 / (2 * sigma**2))\n",
    "            svm.fit(xTraining,yTraining)\n",
    "            per = correctPercentage(svm,xVal,yVal, rango)\n",
    "            perEnt = correctPercentage(svm,xTraining,yTraining, rango)\n",
    "            arrayPer = np.append(arrayPer, per)\n",
    "            arrayPerTraining = np.append(arrayPerTraining, perEnt)\n",
    "            if per >= bestvalue:\n",
    "                bestc = c\n",
    "                bestsigma = sigma\n",
    "                bestvalue = per\n",
    "                bestsvm = svm\n",
    "            print(\"%.2f para C = %.2f y sigma = %.2f\" % (per, c, sigma))\n",
    "            print(\"#%.2f para C = %.2f y sigma = %.2f (entrenamiento)\" % (perEnt, \n",
    "                                                                          c, sigma))\n",
    "            print(\"errorAmmount\", errorAmmountSVM(svm, xVal, yVal))\n",
    "            \n",
    "        bestValuesMatrix = np.append(bestValuesMatrix, arrayPer)\n",
    "        bestValuesMatrixT = np.append(bestValuesMatrixT, arrayPerTraining)\n",
    "\n",
    "        #Dibuja la figura en 2D, comparando cada sigma con cada C\n",
    "        plt.plot(nums, arrayPer, \"-\", color=\"orange\" ,label=\"Validation\")\n",
    "        plt.plot(nums, arrayPerTraining, \"-\", color=\"blue\" ,label=\"Training\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"svm/sigma%i.png\" % k)\n",
    "        k = k + 1\n",
    "\n",
    "    #Dibuja en 3D:\n",
    "    #Los ejemplos de Validación\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    sigma2, c2 = np.meshgrid(nums, nums)\n",
    "    bestValuesMatrix = np.reshape(bestValuesMatrix, c2.shape)\n",
    "    ax.plot_surface(c2, sigma2,\n",
    "                    bestValuesMatrix, cmap=cm.coolwarm, \n",
    "                          linewidth=0, antialiased=False)\n",
    "    \n",
    "    ax.set_xlabel(\"Sigma\")\n",
    "    ax.set_ylabel(\"C\")\n",
    "    ax.set_zlabel(\"Correct percentage\")\n",
    "    ax.set_title(\"Effects on validation examples\")\n",
    "    \n",
    "    #Los ejemplos de entrenamiento\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    bestValuesMatrixT = np.reshape(bestValuesMatrixT, c2.shape)\n",
    "    ax.plot_surface(c2, sigma2,\n",
    "                    bestValuesMatrixT, cmap=cm.coolwarm, \n",
    "                          linewidth=0, antialiased=False)\n",
    "    \n",
    "    ax.set_xlabel(\"Sigma\")\n",
    "    ax.set_ylabel(\"C\")\n",
    "    ax.set_zlabel(\"Correct percentage\")\n",
    "    ax.set_title(\"Effects on training examples\")\n",
    "    \n",
    "    print(\"Mejor porcentaje de acierto sobre los ejemplos de validación: %.2f\" % bestvalue)\n",
    "    \n",
    "    svm = SVC(kernel='rbf', C=30 ,gamma=1 / (2 * 0.01**2))\n",
    "    svm.fit(xTraining,yTraining)\n",
    "\n",
    "    \n",
    "    \n",
    "SVM(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otra implementación igual que la anterior, sin generar gráficos\n",
    "#Incluye opción para pasar los ejemplos por parámetro(data),\n",
    "#Probar con diferentes números de componentes(componentes y Trycomponentes debe\n",
    "#ser True), y para probar con distintos tamaños de grupo con groupsize\n",
    "def SVM2(rango, data=None, TryComponents=False,componentes = 8, groupsize = 1): \n",
    "    if data is None:\n",
    "        xTraining,yTraining,xVal,yVal,xTest,yTest = loadDataShuffled(TryComponents,\n",
    "                                                                     componentes, \n",
    "                                                                     TryComponents, \n",
    "                                                                     groupsize)\n",
    "    else: \n",
    "        xTraining,yTraining,xVal,yVal,xTest,yTest = data\n",
    "        \n",
    "    bestvalue = -1\n",
    "    nums = np.array([0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30])\n",
    "    \n",
    "    for c in nums:\n",
    "        for sigma in nums:\n",
    "            svm = SVC(kernel='rbf', C=c ,gamma=1 / (2 * sigma**2), max_iter=-1)\n",
    "            svm.fit(xTraining,yTraining)\n",
    "            per = correctPercentage(svm,xVal,yVal, rango)  \n",
    "            if per >= bestvalue:\n",
    "                bestc = c\n",
    "                bestsigma = sigma\n",
    "                bestvalue = per\n",
    "                bestsvm = svm\n",
    "    \n",
    "    #Imprime 10 ejemplos\n",
    "    #printExamplesSVM(bestsvm, xTest[0:10], yTest[0:10])\n",
    "    \n",
    "    #print(\"Mejor porcentaje de acierto sobre los ejemplos de validación: %.2f\" % bestvalue)\n",
    "    \n",
    "    return bestvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busca el mejor resultado para el kernel linear y gaussiano y lo devuelve\n",
    "def linearVSGaussian(rango, numT):\n",
    "    xTraining, yTraining, xVal, yVal, xTest, yTest = loadDataShuffled(numTraining=numT)\n",
    "    bestvalue = -1\n",
    "    nums = np.array([0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30])\n",
    "    bestvalueLinear = -1\n",
    "    for c in nums:\n",
    "        for sigma in nums:\n",
    "            svm = SVC(kernel='rbf', C=c ,gamma=1 / (2 * sigma**2), max_iter=-1)\n",
    "            svm.fit(xTraining,yTraining)\n",
    "            per = correctPercentage(svm,xVal,yVal, rango)  \n",
    "            if per >= bestvalue:\n",
    "                bestc = c\n",
    "                bestsigma = sigma\n",
    "                bestvalue = per\n",
    "        svmLinear = SVC(kernel='linear', C=c)\n",
    "        svmLinear.fit(xTraining, yTraining)\n",
    "        perLinear = correctPercentage(svmLinear, xVal, yVal, rango)\n",
    "        if perLinear >= bestvalueLinear:\n",
    "            bestcLinear = c\n",
    "            bestvalueLinear = perLinear\n",
    "        \n",
    "    \n",
    "    #print(\"Mejor porcentaje de acierto sobre los ejemplos de validación: %.2f\" % bestvalue)\n",
    "    #print(\"Mejor porcentaje de acierto sobre los ejemplos de validación (Linear):\n",
    "    #%.2f\" % bestvalueLinear)\n",
    "    \n",
    "    return bestvalue, bestvalueLinear\n",
    "\n",
    "#Ejecuta varias veces linearVSGaussian() para hacer gráficos, comparando\n",
    "#Los resultados de utilizar cada kernel\n",
    "def linearVSGaussianGraphic():\n",
    "    arrayGaussian = np.array([])\n",
    "    arrayLinear = np.array([])\n",
    "    arrayI = np.array([])\n",
    "    for i in range(10):\n",
    "        resGaussian, resLinear = linearVSGaussian(2, 100)\n",
    "        arrayGaussian = np.append(arrayGaussian, resGaussian)\n",
    "        arrayLinear = np.append(arrayLinear, resLinear)\n",
    "        arrayI = np.append(arrayI, i * 2)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Linear vs Gaussian kernel\")\n",
    "    plt.bar(arrayI, arrayGaussian, color = \"sandybrown\", label=\"Gaussian\")\n",
    "    plt.bar(arrayI + 1, arrayLinear, color = \"seagreen\", label=\"Linear\")\n",
    "    plt.ylabel(\"Correct percentage; range = 2\")\n",
    "    plt.legend()\n",
    "    plt.xticks()\n",
    "    plt.ylim((70,80))\n",
    "    plt.savefig(\"svm/LinearGaussian2\")\n",
    "    \n",
    "linearVSGaussianGraphic()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compara la efectividad para cada numero de componentes\n",
    "#dibujando un gráfico sobre ello\n",
    "def aciertosVSnComponentes():\n",
    "    plt.figure()\n",
    "    bestValues = np.array([])\n",
    "    component = np.array([])\n",
    "    for i in range(1, 9):\n",
    "        bestValues = np.append(bestValues, SVM2(0, TryComponents=True, componentes = i))\n",
    "        component = np.append(component, i)\n",
    "    plt.title(\"Correct percentage vs number of components\")\n",
    "    plt.ylabel(\"Correct Percentage\")\n",
    "    plt.xlabel(\"Number of components\")\n",
    "    plt.ylim((np.min(bestValues) - 2, np.max(bestValues) + 2))\n",
    "    plt.bar(component, bestValues, color=\"cornflowerblue\")\n",
    "    plt.savefig(\"svm/AciertosVSComponentes3.png\")\n",
    "    \n",
    "aciertosVSnComponentes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM2(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM(2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1./(1. + np.exp(-1. * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genera una theta inicial con valores aleatorios\n",
    "def pesosAleatorios(Lin, Lout):\n",
    "    ini = 0.12 \n",
    "    theta = np.random.random((Lout,Lin+1))*(2*ini)-ini\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h0(x,theta1,theta2):\n",
    "    z2 = np.matmul(x, theta1.T)\n",
    "    a2 = sigmoide(z2)\n",
    "    a2 = np.hstack((np.ones((a2.shape[0],1)), a2))\n",
    "    \n",
    "    #Capa de salida\n",
    "    z3 = np.matmul(theta2, a2.T)\n",
    "    a3 = sigmoide(z3)\n",
    "    \n",
    "    return a3, a2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo funciona para 1 capa oculta\n",
    "def backdrop(params_rn, num_entradas, num_ocultas, num_etiquetas, x, y, mini, reg = 0 ):\n",
    "    #Desempaqueta los parámetros\n",
    "    theta1 = np.reshape(params_rn[: num_ocultas * (num_entradas + 1) ],\n",
    "                        (num_ocultas , (num_entradas + 1)))\n",
    "    theta2 = np.reshape(params_rn[num_ocultas * (num_entradas + 1) :],\n",
    "                        (num_etiquetas , (num_ocultas + 1)))\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "\n",
    "    #Genera la matriz de etiquetas.\n",
    "    y2 = np.zeros((len(y), num_etiquetas))\n",
    "    #Pone los 1 en la matriz de 0\n",
    "    for i in range(len(y)):\n",
    "        y2[i,int(y[i]) - mini] = 1\n",
    "    \n",
    "    #FORWARD PROPAGATION-------------------------------------------------\n",
    "    a3, a2 = h0(xOnes, theta1, theta2)\n",
    "    a = - y2 * np.log(a3).T\n",
    "    b = (1 - y2) * np.log(1 - a3).T\n",
    "    c = np.sum(1. / (xOnes.shape[0]) * (a - b))\n",
    "    coste = c + (reg/(2 * xOnes.shape[0]))*(np.sum(theta1**2) + np.sum(theta2**2))\n",
    "\n",
    "    #BACKPROPAGATION------------------------------------------------------\n",
    "    delta3 = a3 - y2.T\n",
    "    delta2 = np.matmul(theta2.T, delta3) * (a2.T * (1. - a2.T))\n",
    "    #Copia theta para evitar dañar la original para vectorizar que\n",
    "    #la primera fila no se modifica al regularizar\n",
    "    theta1c = np.copy(theta1)\n",
    "    theta2c = np.copy(theta2)\n",
    "    theta2c[:,0] = theta2c[:,0] * 0  \n",
    "    theta1c[:,0] = theta1c[:,0] * 0\n",
    "    \n",
    "    #Calcula las theta resultantes, incluyendo la regularización\n",
    "    triangulo2 = (np.matmul(delta3, a2) / xOnes.shape[0]) \n",
    "    triangulo2 = triangulo2 + (reg/xOnes.shape[0]) * theta2c\n",
    "    triangulo1 = (np.matmul(delta2[1:], xOnes) / xOnes.shape[0]) \n",
    "    triangulo1 = triangulo1 + (reg/xOnes.shape[0]) * theta1c\n",
    "    \n",
    "    return coste, np.concatenate((triangulo1.ravel(),triangulo2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coste(xOnes, y2, theta1, theta2, reg):\n",
    "    a3, a2 = h0(xOnes, theta1, theta2)\n",
    "    a = - y2 * np.log(a3).T\n",
    "    b = (1 - y2) * np.log(1 - a3).T\n",
    "    c = np.sum(1. / (xOnes.shape[0]) * (a - b))\n",
    "    coste = c + (reg/(2 * xOnes.shape[0]))*(np.sum(theta1**2) + np.sum(theta2**2))\n",
    "    return coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printExamplesSVM pero para Redes neuronales\n",
    "def checkNeural(theta_opt1, theta_opt2, x, y, maxi, mini):\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "    for i in range(xOnes.shape[0]):\n",
    "        salida = h0(xOnes[i,np.newaxis], theta_opt1, theta_opt2)\n",
    "        salida = salida[0].ravel()\n",
    "        print(\"Valores de x: \", xOnes[i])\n",
    "        print(\"El valor predicho es: %i\" % (salida.argmax() + mini % maxi))\n",
    "        print(\"El valor real es: %i\" % int(y[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correctPercentage pero para redes neuronales\n",
    "def correctPercentageNN(theta_opt1, theta_opt2, x, y, maxi, mini, rango):\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "    array = h0(xOnes, theta_opt1, theta_opt2)[0]\n",
    "\n",
    "    result = (np.argmax(array, axis=0) + mini) % maxi\n",
    "    \n",
    "    cmp = np.abs(y - (result)) <= rango \n",
    "    return np.sum(cmp)/len(y)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errorAmmountSVM pero para redes neuronales\n",
    "def errorAmmountNN(theta_opt1, theta_opt2, x, y, maxi, mini):\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "    array = h0(xOnes, theta_opt1, theta_opt2)[0]\n",
    "\n",
    "    result = (np.argmax(array, axis=0) + mini) % maxi\n",
    "    return np.sum(np.abs(result - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrena una red neuronal para un valor discreto de regularización\n",
    "def neuralNetwork(reg, num_ocultas, rango, data = None):\n",
    "    \n",
    "    if data is None:\n",
    "        xTraining, yTraining, xVal, yVal, xTest, yTest = loadDataShuffled()\n",
    "    else:\n",
    "        xTraining, yTraining, xVal, yVal, xTest, yTest = data\n",
    "    num_entradas = xTraining.shape[1]\n",
    "        \n",
    "    #Utiliza el mínimo y máximo para crear el número de etiquetas\n",
    "    maxi = int(np.max([np.max(yTraining), np.max(yVal), np.max(yTest)]))\n",
    "    mini = int(np.min([np.min(yTraining), np.min(yVal), np.min(yTest)]))\n",
    "    num_etiquetas = maxi - mini + 1\n",
    "        \n",
    "    t1 = pesosAleatorios(num_entradas,num_ocultas)\n",
    "    t2 = pesosAleatorios(num_ocultas, num_etiquetas)\n",
    "    params_t = np.vstack((np.reshape(t1, (t1.shape[0]*t1.shape[1],1)),\n",
    "                           np.reshape(t2, (t2.shape[0]*t2.shape[1],1))))\n",
    "    \n",
    "    #Entrena la red neuronal\n",
    "    result = opt.minimize(fun=backdrop, x0=params_t,\n",
    "                          args=(num_entradas, num_ocultas,\n",
    "                                num_etiquetas, xTraining, yTraining, mini, reg),\n",
    "                          method='TNC', jac=True)\n",
    "    \n",
    "    #Desempaqueta la salida del entrenamiento\n",
    "    salida1 = np.reshape(result.x[: num_ocultas * (num_entradas + 1) ], \n",
    "                         (num_ocultas , (num_entradas + 1)))\n",
    "    salida2 = np.reshape(result.x[num_ocultas * (num_entradas + 1) :], \n",
    "                         (num_etiquetas , (num_ocultas + 1)))\n",
    "    \n",
    "    #Imprime 10 ejemplos de test\n",
    "    #checkNeural(salida1, salida2, xTest[0:10], yTest[0:10], maxi, mini)\n",
    "    \n",
    "    return correctPercentageNN(salida1, salida2, xVal, yVal, maxi, mini,0), result.fun\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busca el mejor valor probando con distintas lambdas.\n",
    "#Puedes decidir si se dibujan gráficas o no con plot\n",
    "def neuralNetworkDecide(maxiter, num_ocultas, rango, data=None, plot=True):\n",
    "    \n",
    "    if data is None:\n",
    "        xTraining, yTraining, xVal, yVal, xTest, yTest =  loadDataShuffled()\n",
    "    else:\n",
    "        xTraining, yTraining, xVal, yVal, xTest, yTest = data\n",
    "    \n",
    "    num_entradas = xTraining.shape[1]\n",
    "    \n",
    "    #Utiliza el mínimo y máximo para crear el número de etiquetas,\n",
    "    #Se utiliza el minimo y máximo entre todos los ejemplos, aunque\n",
    "    #no aparezcan en los de entranamineto\n",
    "    maxi = int(np.max([np.max(yTraining), np.max(yVal), np.max(yTest)]))\n",
    "    mini = int(np.min([np.min(yTraining), np.min(yVal), np.min(yTest)]))\n",
    "    num_etiquetas = maxi - mini + 1\n",
    "    \n",
    "    \n",
    "    xValOnes = np.hstack((np.ones((xVal.shape[0],1)), xVal))\n",
    "\n",
    "    #Genera la matriz de etiquetas.\n",
    "    yVal2 = np.zeros((len(yVal), num_etiquetas))\n",
    "    #Pone los 1 en la matriz de 0\n",
    "    for i in range(len(yVal)):\n",
    "        yVal2[i,int(yVal[i]) - mini] = 1\n",
    "    \n",
    "    reg = np.array([0.001, 0.003, 0.007, 0.01, 0.03, 0.07, \n",
    "                    0.1, 0.3, 0.7, 1, 3, 7, 10, 30])\n",
    "    \n",
    "    #Array para almacenar el resultado del coste para cada lambda\n",
    "    errorTra = np.array([])\n",
    "    errorVal = np.array([])\n",
    "    correctPerTra = np.array([])\n",
    "    correctPerVal = np.array([])\n",
    "    #Entrena la red neuronal\n",
    "    t1 = pesosAleatorios(num_entradas,num_ocultas)\n",
    "    t2 = pesosAleatorios(num_ocultas, num_etiquetas)\n",
    "    params_t = np.vstack((np.reshape(t1, (t1.shape[0]*t1.shape[1],1)),\n",
    "                          np.reshape(t2, (t2.shape[0]*t2.shape[1],1))))\n",
    "    for i in reg:\n",
    "  \n",
    "        result = opt.minimize(fun=backdrop, x0=params_t,\n",
    "                              args=(num_entradas, num_ocultas,\n",
    "                                    num_etiquetas, xTraining, yTraining, mini, i),\n",
    "                              method='TNC', jac=True, options={'maxiter': maxiter})\n",
    "    \n",
    "    #Desempaqueta la salida del entrenamiento\n",
    "        salida1 = np.reshape(result.x[: num_ocultas * (num_entradas + 1) ], \n",
    "                             (num_ocultas , (num_entradas + 1)))\n",
    "        salida2 = np.reshape(result.x[num_ocultas * (num_entradas + 1) :], \n",
    "                             (num_etiquetas , (num_ocultas + 1)))\n",
    "        correctPerVal = np.append(correctPerVal,\n",
    "                                  correctPercentageNN(salida1, salida2,\n",
    "                                                      xVal, yVal,\n",
    "                                                      maxi, mini, rango))\n",
    "        correctPerTra = np.append(correctPerTra,\n",
    "                                  correctPercentageNN(salida1, salida2,\n",
    "                                                      xTraining, yTraining,\n",
    "                                                      maxi, mini, rango))\n",
    "\n",
    "        #print(correctPercentageNN(salida1, salida2, xVal, yVal, maxi, mini, rango))\n",
    "        cost = coste(xValOnes, yVal2, salida1, salida2, i)\n",
    "        errorTra = np.append(errorTra, [result.fun])\n",
    "        errorVal = np.append(errorVal, [cost])\n",
    "        #print(\"%.5f para reg = %.3f\" % (cost, i))\n",
    "    if plot:\n",
    "        #Gráfico con el error\n",
    "        plt.figure()\n",
    "        plt.plot(reg, errorTra, \"-\", color=\"blue\", label=\"Training\")\n",
    "        plt.plot(reg, errorVal, \"-\", color =\"orange\", label=\"Validation\")\n",
    "        plt.title(\"Error for neural network\")\n",
    "        plt.xlabel(\"Regularization value\")\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.xscale(\"log\")\n",
    "        plt.savefig(\"nn/reg1\")\n",
    "\n",
    "        #Gráfico con el porcentaje de correctos\n",
    "        plt.figure()\n",
    "        plt.plot(reg, correctPerTra, \"-\", color=\"lightblue\", label=\"Training\")\n",
    "        plt.plot(reg, correctPerVal, \"-\", color =\"tomato\", label=\"Validation\")\n",
    "        plt.title(\"Correct Percentage for neural network\")\n",
    "        plt.xlabel(\"Regularization value\")\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"Correct Percentage (range=2)\")\n",
    "        plt.xscale(\"log\")\n",
    "        plt.savefig(\"nn/reg2\")\n",
    "    #checkNeural(salida1, salida2, xVal[0:20], yVal[0:20], maxi, mini)\n",
    "    return np.max(correctPerVal)#salida1, salida2, result.fun, maxi, mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compara la efectividad para cada numero de nodos en la capa oculta.\n",
    "#Muestra dos graficos con los mismos datos.\n",
    "def aciertosVSnOcultas():\n",
    "    bestValues = np.array([])\n",
    "    minError = np.array([])\n",
    "    component = np.array([])\n",
    "    datos = loadDataShuffled()\n",
    "\n",
    "    for i in range(1,11):\n",
    "        res = neuralNetwork(0., i, 0, data=datos)\n",
    "        bestValues = np.append(bestValues, res[0])\n",
    "        minError = np.append(minError, res[1])\n",
    "        \n",
    "        component = np.append(component, i)\n",
    "\n",
    "    #Gráfica para los porcentajes\n",
    "    plt.figure()\n",
    "    plt.title(\"Number of hidden nodes effects\")\n",
    "    plt.ylabel(\"Correct Percentage\")\n",
    "    plt.xlabel(\"Number of hidden nodes\")\n",
    "    plt.ylim((np.min(bestValues) - 0.2, np.max(bestValues) + 0.2))\n",
    "    plt.bar(component, bestValues, color=\"cornflowerblue\")\n",
    "    plt.savefig(\"nn/AciertosVSnOcultas10.png\")\n",
    "    \n",
    "    #Gráfica para los errores\n",
    "    plt.figure()\n",
    "    plt.title(\"Number of hidden nodes effects\")\n",
    "    plt.ylabel(\"Error value\")\n",
    "    plt.xlabel(\"Number of hidden nodes\")\n",
    "    plt.ylim((np.min(minError) - 0.2, np.max(minError) + 0.2))\n",
    "    plt.bar(component, minError, color=\"yellowgreen\")\n",
    "    plt.savefig(\"nn/AciertosVSnOcultas20.png\")\n",
    "    \n",
    "    \n",
    "aciertosVSnOcultas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = neuralNetworkDecide(1000, 15, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNetwork(0.01, 15, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logistica multicase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de coste\n",
    "def J(theta, x, y, landa):\n",
    "    theta = np.c_[theta] \n",
    "    aux = sigmoide(np.matmul(x, theta))\n",
    "    a = np.log(aux) * y\n",
    "    b = np.log(1 - aux) * (1 - y)\n",
    "    c = - 1 / y.shape[0] * (a + b)\n",
    "    d = landa / (2 * y.shape[0]) * np.sum(theta**2)\n",
    "    return np.sum(c) + d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradiente\n",
    "def descenso(theta, x, y, landa):\n",
    "    theta = np.c_[theta]\n",
    "    a = sigmoide(np.matmul(x,theta)) - y\n",
    "    b = np.matmul(np.transpose(x),a)\n",
    "    c = (1/y.shape[0] * b)\n",
    "    d = landa/y.shape[0] * theta\n",
    "    d[0,0] = 0 \n",
    "    return np.ravel(c + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(x, y, num_etiquetas, reg, mini):\n",
    "    #Crea theta\n",
    "    theta = np.ravel(np.zeros((1,x.shape[1])))\n",
    "    \n",
    "    #Genera la matriz de etiquetas.\n",
    "    y2 = np.zeros((len(y), num_etiquetas))\n",
    "    #Pone los 1 en la matriz de 0\n",
    "    for i in range(len(y)):\n",
    "        y2[i,int(y[i]) - mini] = 1\n",
    "    \n",
    "        \n",
    "    #Crea theta auxiliar para ir guardando los \n",
    "    #resultados de cada optimizacion\n",
    "    theta_opt = np.reshape(theta, (len(theta),1))\n",
    "    \n",
    "    #Ahora para cada etiqueta hacemos el descenso\n",
    "    for i in range(num_etiquetas):\n",
    "        result = opt.fmin_tnc(func=J , x0=theta, fprime=descenso, \n",
    "                              args=(x, np.c_[y2[:,i]], reg)) \n",
    "        theta_opt = np.hstack((theta_opt, np.reshape(result[0],\n",
    "                                                     (len(result[0]),1))))\n",
    "    \n",
    "    #Se devuelve todo menos la primera fila, que se usaba como auxiliar \n",
    "    #para ir creando la matriz\n",
    "    return theta_opt[:,1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y,reg,num_etiquetas, mini):\n",
    "    #Vector de X con unos para operar con theta\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "    \n",
    "    #Devuelve el vector optimizado\n",
    "    return oneVsAll(xOnes,y, num_etiquetas,reg, mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printExamplesSVM o checkNeural para regresión logística\n",
    "def doExamples(x, y, theta, mini, maxi):\n",
    "    \n",
    "    #Vector de x con unos para operar matricialmente con theta\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "    \n",
    "    for i in range(xOnes.shape[0]):\n",
    "        salida = sigmoide(np.matmul(xOnes[i], theta))\n",
    "        print(\"Valores de x: \", xOnes[i])\n",
    "        print(\"El valor predicho es: %i\" % ((salida.argmax() + mini) % maxi))\n",
    "        print(\"El valor real es: %i\" % int(y[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correctPercentage o correctPercentageNN para regresión logística\n",
    "def correctPercentageRL(theta, x, y, maxi, mini, rango):\n",
    "    xOnes = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "\n",
    "    array = sigmoide(np.matmul(xOnes, theta))\n",
    "    result = (np.argmax(array, axis=1) + mini) % maxi\n",
    "    \n",
    "    cmp = np.abs(y - (result)) <= rango \n",
    "    return np.sum(cmp)/len(y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrena para un valor discreto de reg\n",
    "def regresionLogistica(reg, rango, data=None):\n",
    "    \n",
    "    if data is None:\n",
    "        xtrain, ytrain, xval, yval, xtest, ytest = loadDataShuffled()\n",
    "    else:\n",
    "        xtrain, ytrain, xval, yval, xtest, ytest = data\n",
    "        \n",
    "    #Entrena con los ejemplos dados y lambda\n",
    "    maxi = int(np.max([np.max(ytrain), np.max(yval), np.max(ytest)]))\n",
    "    mini = int(np.min([np.min(ytrain), np.min(yval), np.min(ytest)]))\n",
    "    num_etiquetas = maxi - mini + 1\n",
    "    theta = train(xtrain, ytrain, reg, num_etiquetas, mini)\n",
    "    \n",
    "    trainPer = correctPercentageRL(theta, xtrain, ytrain, maxi, mini, rango)\n",
    "    return correctPercentageRL(theta, xval, yval, maxi, mini, rango), trainPer, theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busca el mejor resultado probando con varios valores de lambda\n",
    "def chooseLanda(numTrain, rango, data=None, plot=True):\n",
    "    reg = np.array([0.001, 0.003, 0.007, 0.01, 0.03, 0.07, \n",
    "                    0.1, 0.3, 0.7, 1, 3, 7, 10, 30])\n",
    "    if data is None:\n",
    "        data = loadDataShuffled(numTraining=numTrain)\n",
    "        \n",
    "    xtrain, ytrain, xval, yval, xtest, ytest = data\n",
    "    maxi = int(np.max([np.max(ytrain), np.max(yval), np.max(ytest)]))\n",
    "    mini = int(np.min([np.min(ytrain), np.min(yval), np.min(ytest)]))\n",
    "    \n",
    "    values = np.array([])\n",
    "    valuesTrain = np.array([])\n",
    "    bestPer = -1\n",
    "    for i in reg:\n",
    "        RL = regresionLogistica(i,rango,data)\n",
    "        values = np.append(values, RL[0])\n",
    "        valuesTrain = np.append(valuesTrain, RL[1])\n",
    "        if RL[0] > bestPer:\n",
    "            bestPer = RL[0]\n",
    "            bestPerT = RL[1]\n",
    "            bestTheta = RL[2]\n",
    "            bestLan = i\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.xscale(\"log\")\n",
    "        plt.plot(reg, values, \"-\", c=\"khaki\", label=\"Validation\")\n",
    "        plt.plot(reg, valuesTrain, \"-\", c=\"turquoise\", label=\"Training\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Regularization value\")\n",
    "        plt.ylabel(\"Correct percentage (range=%i)\" % rango)\n",
    "        plt.title(\"Number of examples: %i\" % numTrain)\n",
    "        print(\"Best lambda = %.3f\" % bestLan)\n",
    "        plt.savefig(\"rl/correctPercentage%i\" % numTrain)\n",
    "    \n",
    "    #doExamples(xtest[0:10],ytest[0:10],bestTheta, mini, maxi)\n",
    "    \n",
    "    return bestPer, bestPerT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocesa los ejemplos para hacer polinomios de grado numpoly\n",
    "#y hace la regresión discreta con los parámetros dados\n",
    "def regresionLogisticaPoly(reg, numpoly,data,rango):\n",
    "    xtrain, ytrain, xval, yval, xtest, ytest = data\n",
    "    poly = PolynomialFeatures(numpoly) #Función polinomial\n",
    "    xtrain = poly.fit_transform(xtrain)\n",
    "    xval = poly.fit_transform(xval)\n",
    "    xtest = poly.fit_transform(xtest)\n",
    "    datos = xtrain, ytrain, xval, yval, xtest, ytest\n",
    "    RL = regresionLogistica(reg,rango,datos)\n",
    "    return RL[0], RL[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Busca el mejor tamaño para el polinomio; dibuja la gráfica\n",
    "def bestNumPoly(rango):\n",
    "    percentages = np.array([])\n",
    "    percentagesT = np.array([])\n",
    "    k = np.array([])\n",
    "\n",
    "    data = loadDataShuffled()\n",
    "    \n",
    "    #Solo 4, por el gran coste computacional.\n",
    "    for i in range(1,5):\n",
    "        bestValues = regresionLogisticaPoly(0.01,i,data,rango)\n",
    "        percentages = np.append(percentages, bestValues[0])\n",
    "        percentagesT = np.append(percentagesT, bestValues[1])\n",
    "        k = np.append(k, i)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Polinomy degree\")\n",
    "    plt.ylabel(\"Correct Percentage (range=%i)\" % rango)\n",
    "    plt.plot(k, percentages, \"-\", c=\"darkorchid\", label=\"Validation\")\n",
    "    plt.plot(k, percentagesT, \"-\", c=\"greenyellow\", label=\"Training\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"rl/bestnumpoly\")\n",
    "\n",
    "        \n",
    "bestNumPoly(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busca cual es el mejor número de ejemplos de entrenamiento, \n",
    "#dibujando gráficos.\n",
    "def bestNumTraining():\n",
    "    numTraining = np.array([5,10, 20,50,100,300, \n",
    "                            600, 1000, 1500, 2000, 2500,\n",
    "                            3000, 3500])\n",
    "    percentages = np.array([])\n",
    "    percentagesT = np.array([])\n",
    "    \n",
    "    \n",
    "    for i in numTraining:\n",
    "        bestValues = chooseLanda(i, 0, plot=False)\n",
    "        percentages = np.append(percentages, bestValues[0])\n",
    "        percentagesT = np.append(percentagesT, bestValues[1])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of training examples\")\n",
    "    plt.ylabel(\"Correct Percentage\")\n",
    "    plt.plot(numTraining, percentages, \"-\", c=\"orchid\", label=\"Validation\")\n",
    "    plt.plot(numTraining, percentagesT, \"-\", c=\"darkseagreen\", label=\"Training\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"rl/NTrainingExamplesVSCorrectPercentage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestNumTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chooseLanda(3000, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaciones entre los 3 métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestResults(rango, datos):\n",
    "    #Regresión lineal\n",
    "    bestPerRL = chooseLanda(3000, rango, data=datos, plot=False)[0]\n",
    "    \n",
    "    #Neural Network\n",
    "    bestPerNN = neuralNetworkDecide(1000, 15, rango, data=datos, plot=False)\n",
    "    \n",
    "    #SVM\n",
    "    bestPerSVM = SVM2(rango, data=datos)\n",
    "        \n",
    "    resultsArray = [bestPerRL, bestPerNN, bestPerSVM]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Best result obtained\")\n",
    "    plt.ylabel(\"Correct percentage (range=%i)\" % rango)\n",
    "    plt.ylim((np.min(resultsArray)-0.5, np.max(resultsArray)+0.5))\n",
    "    plt.bar([\"Regresión lineal\", \"Red neuronal\", \"Support Vector Machine\"],\n",
    "            [bestPerRL, bestPerNN, bestPerSVM], \n",
    "            color=[\"darkorchid\", \"gold\", \"dodgerblue\"])\n",
    "    plt.savefig(\"graph/comparisonrange%i\" % rango)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba con tres márgenes de errores y los mismos datos\n",
    "#de entrenamiento\n",
    "def bestResultsRangos():\n",
    "    datos = loadDataShuffled()\n",
    "    bestResults(0, datos)\n",
    "    bestResults(1, datos)\n",
    "    bestResults(2, datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestResultsRangos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
